<!DOCTYPE html>
<html>
    <head>
        <title>GSBPM version 5.2</title>
        <meta http-equiv='Content-Type' content='text/html;charset=utf-8' />
        <script src='https://www.w3.org/Tools/respec/respec-w3c' class='remove' defer></script>
        <script class='remove'>
            var respecConfig = {
                // specStatus: "unofficial",
                noRecTrack: true,
                shortName: "GSBPMv5.2",
                subtitle: "Generic Statistical Business Process Model (Version 5.2)",
                 latestVersion: "https://unece.github.io/GSIM-2.0/",
                // publishDate:  "2022-xx-xx",
                wg: "High-Level Group for the Modernisation of Official Statistics",
                wgURI: "https://statswiki.unece.org/display/hlgbas/Modernisation+Groups",
                wgPatentURI: "https://creativecommons.org/licenses/by/3.0/igo/",
                github: {
                    repoURL: "https://github.com/UNECE/GSBPM-5.2",
                    branch: " ", // avoids default 'gh-pages' 
                },
            };
        </script>
  <style>
    body {
      counter-reset: h1;
    }
    h1::before {
      content: none;
    }
  </style>
    </head>
    <body>
        <section id="abstract">
            <!-- <img src="https://upload.wikimedia.org/wikipedia/commons/e/e1/CC_BY_icon.svg"> -->
            <p class="copyright" style="font-size:15px;" > This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/">the Creative Commons Attribution 4.0 International License</a>. If you re-use all or part of this work, please attribute it to the United Nations Economic Commission for Europe (UNECE), on behalf of the international statistical community. </p>
            <p>This is the GitHub repository for version 5.2 of the Generic Statistical Business Process Model (GSBPM). You can use the sidebar to navigate different sections of this page. </p>

        </section>

        <section> 
            <h1>1. Introduction</h1>
            <p> 1. The Generic Statistical Business Process Model (GSBPM) describes and defines a set of activities involved in the business processes needed to produce official statistics. It provides a standard framework and harmonised terminology to help statistical organisations to modernise their statistical production processes, as well as to share methods and components. The GSBPM can also be used for integrating data and metadata standards, as a template for process documentation, for harmonising statistical computing infrastructures, and to provide a framework for process quality assessment and improvement. These and other purposes for which the GSBPM can be used are elaborated further in Sections II and VII. This version of the GSBPM is aligned with version 2.0 of the Generic Statistical Information Model (GSIM) and version 1.2 of the Generic Activity Model for Statistical Organisations (GAMSO). </p> 
            <p> <b> Background </b> </p>
            <p> 2. The GSBPM was first developed in 2008 by the Joint UNECE/Eurostat/OECD Group on Statistical Metadata (METIS) based on the business process model used by Statistics New Zealand. Following several drafts and public consultations, version 4.0 of the GSBPM was released in April 2009. Subsequently, it was widely adopted by the global official statistics community, and formed one of the cornerstones of the High-Level Group for the Modernisation of Official Statistics (HLGMOS)<a href="#footnote-1">[1]</a>. vision and strategy for standards-based modernisation. </p>
            <p> 3. Version 5.0 of the GSBPM was released in December 2013 and endorsed by the Conference of European Statisticians in June 2017. A broad review of GSBPM was conducted during 2017-2018 to incorporate feedback based on practical implementation and to improve consistency with new HLG-MOS models, the GSIM and the GAMSO, leading to the release of version 5.1 which was endorsed by the Conference of European Statisticians in June 2019. Subsequently a further review was conducted during 2023-2024, resulting in the present version 5.2 of the GSBPM described within this document. </p>
        
            <p> <b> Main Changes from Version 5.1 </b> </p>
            <p> 4. The main changes to the GSBPM between versions 5.1 and 5.2 include the following: 
            <ol type="a"> 
                <li> Improved or reworked descriptions or explanations:  </li>
                    <ul style="list-style-type:disc;">
                        <li> Extra explanation of the approach toward respondents and users.</li>
                        <li> Greater emphasis for administrative and other non-survey sources of data.</li>
                        <li> The non-sequential nature of the GSBPM has been emphasised by adding an illustration of iteration between sub-processes.</li>
                        <li> Extra descriptions for the Overarching Activities of Process Data Management, Knowledge Management, Data Supplier Management. </li>
                        <li> The role of unit types in distinguishing between concepts from variables.</li>
                        <li> Distinction between data and products.</li>
                        <li> Better signposting to distinguish different parts of the GSBPM and how they relate. </li>
                    </ul>
                <li> Modernised terminology, especially in reference to particular technologies. </li>
                <li> Topics reflected or emphasised due to feedback received, such as: </li>
                    <ul style="list-style-type:disc;">
                       <li>	Extra mentions of machine learning/artificial intelligence.</li>
                       <li> Several further references to geospatial considerations.</li>
                       <li> Factors that could be considered within a business case.</li>
                       <li> Development approaches that iterate between the Design and Build phases and the importance of considering security in those phases.</li>
                       <li> Design of fieldwork operations.</li>
                       <li> Multi-mode collection.</li>
                       <li> Pseudo-anonymisation.</li>
                       <li> Microdata as a possible the output in itself.</li>
                       <li> Cataloguing, tagging and discoverability of statistical outputs.</li>
                    </ul>
                <li> According to different structural levels:  </li>
                    <ul style="list-style-type:disc;">
                       <li>Overarching Processes: Renamed as “Overarching Activities” to enhance alignment with GAMSO (within which GSBPM is nested), their description has been moved ahead of that for phases and sub-processes.</li>
                        <li>Phases and sub-processes: No phases or sub-processes were added or removed; however some sub-processes were renamed to make their meaning and purpose clearer.</li>
                    </ul>
            </ol> 
            <p id="footnote-1">[1] UNECE Statistics Wikis - HLG-MOS (https://statswiki.unece.org/display/hlgbas) </p>
        </section>
        
        <section> 
            <h1>The Model </h1>
            <p> <b> Understanding the GSBPM </b> </p>
            <p> 6.	A statistical business process involves a collection of related and structured activities and tasks to convert inputs into outputs. In the context of the GSBPM, organisations or groups of organisations perform statistical business processes to create official statistics to satisfy the needs of the users. The output of the process may be a mixed set of physical or digital products presenting data and metadata in different ways, such as publications, maps, and/or electronic services, among others.             </p>

            <p> 7.	The GSBPM should be applied and interpreted flexibly. It is <u> not a rigid framework in which all steps must be followed in a strict order</u>, instead it identifies the possible activities that may be performed as steps in a statistical business process and the inter-dependencies between them. </p>

            <p> 8.	GSBPM is inherently <u> non-sequential </u>, allowing flexibility in revisiting phases or sub-processes as needed. While the model is often presented sequentially for clarity, in practice, activities may occur in parallel, repeat in loops, or be omitted depending on specific requirements or circumstances, as depicted in Figure 1. </p>
            
            <img src="./img/GSBPMv5.2_Figure1.png" alt="Alt text here">
            
            <p> 9.	In many statistical organisations, the first few phases are only considered when a new output is created or when the process is revised as a result of an evaluation process. Once the output becomes part of “normal” ongoing activity, these phases are not always undertaken (for example, it is not necessary to build new collection tools every time labour force survey data are collected). Figure 2 depicts this.           </p>
            
            <img src="./img/GSBPMv5.2_Figure2.png" alt="Alt text here">
            
            <p> 10.	The GSBPM should therefore be seen more as a matrix, through which there are many possible paths. In this way, the GSBPM aims to be sufficiently generic to be widely applicable and to encourage a standard view of the statistical business process, without becoming either too restrictive or too abstract and theoretical. The GSBPM supports modularisation of statistical production, for example by allowing often-performed steps to be performed by a reusable software component, perhaps shared across a statistical organisation or even across multiple organisations.   </p>

            <p> 11.	The GSBPM considers a number of different entities to be considered by a statistical business process, such as: </p>
                <ul style="list-style-type:disc;">
                    <li> <b>Users </b>: Consumers of statistical outputs (e.g., policymakers, researchers, businesses, and the public). </li>
                    <li> <b>Respondents</b>: Entities providing information about themselves or others (primary data) to statistical organisations or other producers of official statistics through forms, surveys, or polls. </li>
                    <li> <b>Data holders</b>: Custodians of datasets generated or collected for non-statistical purposes, such as government agencies, private companies, or registry managers, who may or may not provide data to NSOs. </li>
                    <li> <b>Data suppliers</b>: Data holders supplying data to NSOs, including administrative, geospatial, or other non-survey data. </li>
                    <li> <b>Stakeholders</b>: A broad category encompassing users, respondents, data suppliers, data holders, and other parties involved in or affected by the statistical process. </li>
                </ul> 

            <p> <b> Structure </b> </p>
            <p> 12.	The GSBPM comprises three main levels, with the extension to an optional extra lower level of “tasks” that are described in Annex I, as follows:</p>

                <ul style="list-style-type:disc;">
                    <li> <b>Level 0</b>, the statistical business process; </li>
                    <li> <b>Level 1</b>, the eight phases of the statistical business process; </li>
                    <li> <b>Level 2</b>, the sub-processes within each phase; </li>
                    <li> <b>Level 3</b>, the tasks within each sub-process. </li>
                </ul>

            <p> 13.	A diagram showing the phases (level 1) and sub-processes (level 2) is included in Section IV (Figure 5). The sub-processes are described in detail in Section VI.</p>

            <p> 14.	The GSBPM recognises several activities with a strong statistical component that apply throughout the eight phases, called “Overarching Activities” in the model. These overarching activities are listed below and elaborated further in Section V: 
                <ul style="list-style-type:disc;">
                    <li> <b> Quality Management</b> - This overarching activity includes quality assessment and control mechanisms. It recognises the importance of evaluation and feedback throughout the statistical business process; </li>
                    <li> <b> Metadata Management </b> - Metadata are created/reused and processed within each phase, so there is a strong requirement for metadata management to ensure the appropriate metadata retain their links with data throughout the GSBPM. This includes process-independent considerations such as metadata custodianship and ownership, quality, archiving rules, preservation, retention and disposal; </li>
                    <li> <b> Data Management </b>- This includes process-independent considerations such as general data security, custodianship, and ownership, data quality, archiving rules, preservation, retention and disposal; </li>
                    <li> <b> Process Data Management </b>- This includes activities of registering, systematising and using data about the implementation of the statistical business process. Process data can aid in detecting and understanding patterns in the data collected, as well as in evaluating the execution of the statistical business process as such;  </li>
                    <li> <b> Knowledge Management</b> - An ongoing activity that mainly involves maintaining the documentation of recurring statistical business processes, ensuring that they are repeatable; </li>
                    <li> <b> Data Supplier Management </b>- This includes cross-process burden management, as well as topics such as profiling and management of contact information (and thus has particularly close links with statistical business processes that maintain registers). </li>
                </ul>

            <p> <b>Applicability </b> </p>
            <p> 15.	The GSBPM is intended to apply to all activities undertaken by producers of official statistics at both the national and international levels, which result in data outputs.

            <p> 16.	The model is designed to be applicable regardless of the data source, so it can be used for the design, description, management and quality assessment of processes based on surveys, censuses, administrative sources, and other sources that are primarily collected for non-statistical purposes but may be utilised for statistical production, including the following (non-exclusive) types:

                <ul style="list-style-type:disc;">
                    <li> <b> Administrative data</b>: Data generated through routine administrative operations by public entities, such as tax records, health registries, or school enrolments.
                    <li> <b> Privately held data</b>: Data generated through routine operations by private entities, such as commercial transactions, digital platform records, or social media interactions.
                    <li> <b>“Big Data”</b>: High-volume, high-velocity, and high-variety data derived from digital technologies, such as social media activity, mobile device usage, and sensor networks.
                    <li> <b>Geospatial data</b>: Data containing geographic or locational attributes, including satellite imagery, GPS data, and mapping systems, which GSBPM considers in a statistical context<a href="#footnote-2">[2]</a>.  
                </ul>
                
            <p> 17.	Whilst typical statistical business processes include collecting and processing data to produce statistical outputs, the GSBPM also applies when existing data are revised, or time-series are re-calculated, either as a result of improved source data or a change in methodology. In these cases, the input data can be original microdata and/or additional data, which are then processed and analysed to produce revised outputs. In such cases, it is likely that several sub-processes and possibly some phases (particularly the early ones) would be omitted. Similarly, the GSBPM can be applied to processes such as the compilation of national accounts and the typical processes in international statistical organisations that use secondary data from countries or other organisations.</p>

            <p> 18.	As well as being applicable for processes which result in statistical outputs, the GSBPM can also be applied to the development and maintenance of statistical registers, where the inputs are similar to those for statistical production (though typically with a greater focus on administrative data), and the outputs are typically frames or other data extractions, which are then used as inputs to other processes. </p>

            <p> 19.	Artificial intelligence (AI) and machine learning (ML) play an increasingly prominent role in statistical production, facilitating the automation of manual tasks and utilisation of new types of data, and ML is referenced where strongly pertinent, notably in the processing and analysis phases. AI and ML have the potential to be powerful tools in the context of the statistical production process, but also need to be used appropriately, for example to ensure the validity of any outputs produced. However, GSBPM remains applicable irrespective of specific technologies or methods used to carry out the activities in the process. </p>

            <p> 20.	The GSBPM is sufficiently flexible to apply in all of the above scenarios.</p>

            <p> <b> Using the GSBPM</b> </p>
            <p> 21.	The GSBPM is a reference model. It is intended that the GSBPM may be used by organisations to different degrees. An organisation may choose to either use the GSBPM directly or use it as the basis for developing a customised version of the model. It may be used in some cases only as a model to which organisations refer when communicating internally or with other organisations to clarify discussions. The various scenarios for the use of the GSBPM are all valid. </p>

            <p> 22.	When organisations have developed organisation-specific adaptions of the GSBPM, they may make some specialisations to the model to fit their organisational context. Such specialisations may be considered for incorporation within future versions of GSBPM if sufficiently generic and widely supported.  </p>

            <p> 23.	In some cases, it may be appropriate to group some of the elements of the model. For example, the initial three phases could be considered to correspond to a single planning phase. In other cases, particularly for practical implementations, there may be a need to specify components of sub-processes in more detail, and for this purpose, some earlier work on lower-level “Tasks” is provided in Annex 1. </p>

            <p> 24.	There may also be a requirement for a formal sign-off between phases or sub-processes, where the output from one phase is certified as suitable as input for the next. This formal approval is implicit in the model (except in the sub-process 1.6) but may be explicitly implemented in different ways depending on organisational requirements. </p>

            <p id="footnote-2">[2] For those who are only interested in examining the role of GSBPM in relation to geospatial data, a useful resource is the work on GeoGSBPM, undertaken under the auspices of the HLG-MOS (https://statswiki.unece.org/display/GSBPM/GeoGSBPM) </p>
        </section>
        
        <section> 
            <h1>III. Relationships with Other Models and Frameworks </h1>
            <p> 25.	Since the release of the GSBPM, several models have been developed under the auspices of the HLG-MOS to support the modernisation of official statistics, collectively referred to as the “ModernStats” models. The following paragraphs outline the ModernStats models that have a strong link to the GSBPM </p>
            <p> <b> GAMSO </b> </p>
            <p> 26.	The GAMSO<a href="#footnote-3">[3]</a> complements and extends the GSBPM by describing and defining activities that take place within a typical statistical organisation that are either not directly related to the production of statistics or that are managed at a corporate or strategic level (i.e. activities in the areas of strategy and leadership, capability development and corporate support). </p>

            <p> 27.	Such activities include human resource management, and quality management activities that are carried out at the corporate level such as development of a quality framework, among others. GAMSO includes high level descriptions of these activities. GSBPM is nested within GAMSO and comprises its “production” activity area, as depicted in Figure 3. </p>
            
            <img src="./img/GSBPMv5.2_Figure3.png" alt="Alt text here">
            
            <p> 28.	 Like the GSBPM, the GAMSO aims to provide a common vocabulary and framework to support international collaboration activities. Greater value will be obtained from the GAMSO if it is applied in conjunction with the GSBPM. </p>
            
            <p> <b> GSIM </b> </p>
            <p> 29.	The GSIM<a href="#footnote-4">[4]</a>  is a reference framework for statistical information, designed to help modernise official statistics at both national and international levels. It enables generic descriptions of the definition, management and use of information (i.e. data and metadata) throughout the statistical production process. It provides a set of standardised, consistently described information classes, which are the inputs and outputs for GSBPM sub-processes. The GSIM helps to explain significant relationships among the entities involved in statistical production, and can be used to guide the development and use of consistent implementation standards or specifications.</p>

            <p>30.	Like the GSBPM, the GSIM is one of the cornerstones for modernising official statistics and moving away from subject matter silos. It identifies around 130 information classes, examples of which include data sets, variables, statistical classifications, units, populations as well as the rules and parameters needed for production processes to run (e.g. data editing rules).</p>

            <p>31.	The GSIM and the GSBPM are complementary models for the production and management of statistical information. As shown in Figure 4 below, the GSIM helps to describe the GSBPM sub-processes by defining the information classes that flow between them, that are created within them, and that are used by them to produce official statistics. Inputs and outputs can be defined in terms of information classes and are formalised in the GSIM.</p>

            <img src="./img/GSBPMv5.2_Figure4.png" alt="Alt text here">
            
            <p>32.	Greater value will be obtained from the GSIM if it is applied in conjunction with the GSBPM. Likewise, a greater value will be obtained from the GSBPM if it is applied in conjunction with the GSIM. Nevertheless, it is possible (although not ideal) to apply one without the other. </p>

            <p>33.	Applying the GSIM and the GSBPM together can facilitate the building of efficient metadata-driven systems and help to harmonise statistical computing infrastructures<a href="#footnote-5">[5]</a>. </p>
            
            <p id="footnote-3">[3] UNECE Statistics Wikis - GAMSO (https://statswiki.unece.org/display/GAMSO) </p>
            <p id="footnote-4">[4] GSIM 2.0 GitHub repository (https://unece.github.io/GSIM-2.0/GSIMv2.html) </p>
            <p id="footnote-5">[5] Examples of linking particular GSIM classes with GSBPM sub-processes can be found within the report “Linking GSBPM and GSIM” (https://statswiki.unece.org/spaces/GSBPM/pages/330370507/Information+flow+within+GSBPM+using+GSIM) </p>
        </section>
        
        <section> 
            <h1>IV. Levels 1 and 2 of the GSBPM </h1>
            
            <img src="./img/GSBPMv5.2_Figure5.png" alt="Alt text here">
        </section>      
        
        <section> 
            <h1>Descriptions of Overarching Activities </h1>
        
            <p> 34.	The GSBPM recognises several overarching activities that apply throughout the production phases, and across statistical business processes. For example, quality is monitored and checked at various stages of the production. Management of data and metadata is done throughout the process, not at a certain sub-process only. While the production process involves different units and expertise in the organisation at different stages, it is important that these overarching activities are conducted in a consistent manner in accordance with organisation-wide standards and policies, and with close coordination with a central unit. </p>

            <p> 35.	These overarching activities are listed in Section II and elaborated further in the following subsections. Activities that are carried out at the level of the organisation to support the statistical production are included in the GAMSO (see Section III).</p>

            <img src="./img/GSBPMv5.2_OA_QM.png" alt="Alt text here">
            <p> <b> Quality Management </b> </p>
 
            <p> 36.	The quality management overarching activity of GSBPM refers specifically to the management of product and process quality that takes place within the scope of the production process. </p>

            <p> 37.	More broadly, the concept of quality concerns organisations, products, sources and processes. Quality at an institutional level (e.g. adoption of a Quality Policy or Quality Assurance Framework) or in areas that are not directly related to the production (e.g., quality of new employee onboarding programme) is considered in the GAMSO. </p>

            <p> 38.	The main goal of quality management within the statistical business process is to understand and manage the quality of the statistical sources, processes and products. There is general agreement among statistical organisations that quality should be defined according to the ISO 9000-2015 standard: “The degree to which a set of inherent characteristics of an object fulfils requirements"<a href="#footnote-6">[6]</a>. Thus, quality is a complex and multi-faceted concept, usually defined in terms of several quality dimensions. The dimensions of quality that are considered most important depend on user perspectives, needs and priorities, which vary between processes and across groups of users.</p>

            <p> 39.	In order to improve quality, quality management should be present throughout the business process model. It is closely linked to the Evaluate phase, however, quality management has both a deeper and broader scope. As well as evaluating iterations of a process, it is also necessary to evaluate separate phases and sub-processes, ideally each time they are applied, but at least according to an agreed schedule<a href="#footnote-7">[7]</a>. Metadata generated by the different sub-processes themselves are also of interest as an input for process quality management. These evaluations can apply within a specific process, or across several processes that use common components. In addition, a fundamental role in quality management is played by the set of quality control actions that should be implemented within the sub-processes to prevent and monitor errors and sources of risks. These should be documented, and can be used for quality reporting. </p>

            <p> 40.	Within an organisation, quality management will usually refer to a specific quality framework, and may therefore take different forms and deliver different results within different organisations. The current multiplicity of quality frameworks enhances the importance of the benchmarking and peer review approaches to evaluation, and whilst these approaches are unlikely to be feasible for every iteration of every part of every statistical business process, they should be used in a systematic way according to a pre-determined schedule that allows for the review of all main parts of the process within a specified time period<a href="#footnote-8">[8]</a>.</p>

            <p> 41.	Broadening the field of application of the quality management overarching activity, evaluation of groups of statistical business processes can also be considered, in order to identify potential duplication or gaps.

            <p> 42.	All evaluations result in feedback, which should be used to improve the relevant process, phase or sub-process, creating a quality loop that reinforces the approach to continuous improvements and organisational learning. The Quality loop has four main stages: 
                <ul style="list-style-type:disc;">
                    <li> <b> Plan </b>: The Plan stage refers mainly to the first three phases of GSBPM. Selecting a quality framework or designing one must be part of the design of the production process, to have the means of producing information needed to manage quality of the process and of the statistical products; </li>
                    <li> <b> Run</b>: When running the process, care must be taken to compile data and metadata for quality management, with updated data and metadata coming from performing each phase of GSBPM; </li>
                    <li> <b> Evaluate</b>: Assessment of quality indicators must be made throughout the process to make any needed correction on time. During the Evaluate phase, a summary and analysis of the quality information gathered together with any change made during the process will generate conclusions about any improvements that may be needed; </li>
                    <li> <b> Improve</b>: In response to the quality assessment, any needed improvements to the process can be applied, and then reflected during the Plan stage of the cycle.</li>
                </ul> 
                
            <p> 43.	Examples of quality management activities include:</p>

                <ul style="list-style-type:disc;">
                    <li> Assessing risks and implementing risk treatments to ensure fit-for-purpose quality;</li>
                    <li> Setting quality criteria to be used in the process;</li>
                    <li> Setting process quality targets and monitoring compliance;</li>
                    <li> Seeking and analysing user feedback;</li>
                    <li> Reviewing operations and documenting lessons learned;</li>
                    <li> Examining process metadata and quality indicators;</li>
                    <li> Internal or external auditing on the process.</li>
                </ul> 
                
            <p> 44.	Quality indicators support a process-oriented quality management. A suggested list of quality indicators for phases and sub-processes of the GSBPM as well as for the overarching quality and Metadata Management processes can be found at the Quality Indicators for the GSBPM – for Statistics derived from Surveys and Administrative Data Sources<a href="#footnote-9">[9]</a>. Among others, they can be used as a checklist to identify gaps and/or duplication of work in the organisation. </p>
          
            <p> <b> Metadata Management </b> </p>
            <img src="./img/GSBPMv5.2_OA_MM.png" alt="Alt text here">
 
            <p> 45.	Metadata has an important role and must be managed at an operational level within the statistical production process, in accordance with relevant corporate policies and standards. When aspects of metadata management are considered at corporate or strategic level (e.g. there are metadata systems that impact large parts of the production system), it should be considered in the framework of the GAMSO. 

            <p> 46.	Good metadata management is essential for the efficient operation of statistical business processes. Metadata are present in every phase, either created, updated or carried forward from a previous phase or reused from another business process. In the context of this model, the emphasis of the overarching activity of metadata management is on the design/creation/revision, updating, use, and archiving of statistical metadata, though metadata on the different sub-processes themselves are also of interest, including as an input for quality management. The key challenge is to ensure that these metadata are captured as early as possible, and stored and transferred from phase to phase alongside the data they refer to. Metadata management strategy and systems are therefore vital to the operation of this model, and these can be facilitated by the GSIM.

            <p> 47.	The GSIM supports a consistent approach to metadata, facilitating the primary role for metadata, that is, that metadata should uniquely and formally define the content and links between information classes and processes in the statistical information system.

            <p> <b> Data Management </b> </p>
            <img src="./img/GSBPMv5.2_OA_DM.png" alt="Alt text here">
 
            <p> 48.	Data management is essential as data are produced within many of the activities in the statistical business process and are the key outputs. The main goal of data management is to ensure that data are appropriately used and usable throughout their lifecycle. Managing data throughout their lifecycle covers activities such as planning and evaluation of data management processes as well as establishing and implementing processes related to collection, organisation, use, protection, preservation and disposal of the data. 

            <p> 49.	How data are managed will be closely linked to the use of the data, which in turn is linked to the statistical business process where the data are created. Both data and the processes in which they are created must be well defined in order to ensure proper data management.

            <p> 50.	Examples of data management activities include:

                <ul style="list-style-type:disc;">
                    <li> Designing data structures and associated data sets, and the provenance and flow of data through the statistical business process;</li>
                    <li> Identifying database (repositories) to store the data and administration of the database;</li>
                    <li> Documenting the data (e.g. registering and inventorying data, classifying data according to content, retention or other required classification);</li>
                    <li> Determining retention periods of data and archiving;</li>
                    <li> Securing data against unauthorised access and use;</li>
                    <li> Safeguarding data against technological change, physical media degradation, data corruption;</li>
                    <li> Performing data integrity checks (e.g. periodic checks providing assurance about the accuracy and consistency of data over its entire lifecycle);</li>
                    <li> Performing disposition activities once the retention period of the data is expired.</li>
                </ul> 

            <p> <b> Process Data Management </b> </p>
            <img src="./img/GSBPMv5.2_OA_PDM.png" alt="Alt text here">
 

            <p> 51.	The Process Data Management overarching activity within GSBPM refers to the management of process data that takes place within the scope of the production process. Activities related to management of process data at the corporate level should be considered in the framework of the GAMSO.

            <p> 52.	This overarching activity includes activities of registering, systematising, and using data arising from carrying out the statistical business process. This could include, for example, paradata <a href="#footnote-10">[10]</a>, logs resulting from the execution of code, as well as information arising from fieldwork. This data is not quality information in itself, as it may be very detailed (such as the length of time taken by a single field worker to conduct a single interview), but it could possibly be used to derive quality information (such as total or average time for conducting interviews).

            <p> 53.	Such process data can be reviewed to evaluate how the statistical business process is carried out, for example to optimise its efficiency, or to detect possible problems that have occurred and reveal their cause. Process data could also be used to detect and understand patterns in the data used to produce statistics.


            <p> <b> Knowledge Management </b> </p>
            <img src="./img/GSBPMv5.2_OA_KM.png" alt="Alt text here">

            <p> 54.	The Knowledge Management overarching activity refers to the management of knowledge specific to the production process. Activities related to knowledge management at the corporate level should be considered in the framework of the GAMSO, such as GAMSO’s Manage Information and Knowledge, under its Corporate Support area.

            <p> 55.	This Knowledge Management overarching activity within GSBPM refers specifically to the updating of documentation for the production process (e.g. handbooks, manuals, guidance notes already created within sub-process 3.7 (Finalise production systems)) based on knowledge about it. Managing knowledge in a systematic way using such documentation allows it to inform and improve the production process. It can be taken into account when developing training for those who produce statistics, and can also inform evaluation of the production process.

            <p> 56.	Knowledge can be derived from a diverse array of sources, including the experience obtained from each of the individuals involved in the process, which may relate to the code of algorithms, software programmes and scripts used along the statistical lifecycle, good practices, or lessons learned. Reference metadata, analysis of paradata, incidents, process logs, data anomalies, and other subproducts of the statistical process execution, while not knowledge in themselves, can all lead to useful knowledge about the production process which can be documented in order to be passed on to others.

            <p> <b> Data Supplier Management </b> </p>
            <img src="./img/GSBPMv5.2_OA_DSM.png" alt="Alt text here">
 
            <p> 57.	The Data Supplier Management overarching activity within GSBPM refers to the management of data suppliers that takes place within the scope of the production process. Activities related to management of data suppliers at the corporate level should be considered in the framework of the GAMSO, such as in its Manage Data Suppliers activity under Corporate Support.

            <p> 58.	Building on GAMSO's corporate support activity Manage Data Suppliers, which emphasises managing data suppliers, such as ensuring compliance with agreements, this overarching activity within GSBPM extends to technical-level engagement with data suppliers, including those supplying registers.

            <p> 59.	This overarching activity can include:

                <ul style="list-style-type:disc;">
                    <li> Requiring specific information about the input data when metadata and/or documentation are scarce;</li>
                    <li> Asking for assistance from the data supplier to overcome technical or operational issues; and/or</li>
                    <li> Requesting additional information in case of unexpected changes in the data received.</li>
                    <li> Cross-process burden management, profiling and management of contact information (e.g. within registers).</li>
                </ul> 
                
          <p id="footnote-6">[6] ISO 9000:2015, Quality management systems - Fundamentals and vocabulary. International Organization for Standardization</p>
          <p id="footnote-7">[7] A suggested list of quality indicators for the GSBPM which can be used as a reference or a checklist to identify gaps and/or duplication of work in the organisation can be found at the Quality Indicators for the GSBPM – for Statistics derived from Surveys and Administrative Data Sources (https://statswiki.unece.org/display/GSBPM/Quality+Indicators) </p>
          <p id="footnote-8">[8] A suitable global framework is the National Quality Assurance Framework developed by a global expert group under the United Nations Statistical Commission (https://unstats.un.org/unsd/methodology/dataquality/un-nqaf-manual/)  </p> 
          <p id="footnote-9">[9] UNECE Statistics Wikis - Quality Indicators for the GSBPM (https://statswiki.unece.org/display/GSBPM/Quality+Indicators) </p>
          <p id="footnote-10">[10] Process metadata, or data about the process by which the data were collected. </p>
          
    </section>
    
    <section> 
        <h1> Descriptions of Phases and Sub-processes </h1> 
                
            <p> 60.	This section considers each phase in turn, identifying the various sub-processes within that phase and describing their contents.

        <h2> Specify Needs Phase   </h2> 
            <img src="./img/GSBPMv5.2_Phase1.png" alt="Alt text here">
            
Figure 7. Specify needs phase and its sub-processes

            <p> 61.	This phase is triggered when a need for new statistics is identified, perhaps resulting from user feedback, or a review is undertaken. It includes all activities associated with engaging stakeholders to identify their detailed statistical needs (current or future), proposing high level solution options and preparing a business case, which may weigh the benefits of addressing these needs against expected costs, risks and other requirements, considering the public good arising from meeting those needs and the implications for respondents, users and other stakeholders.

            <p> 62.	The Specify Needs phase is broken down into six sub-processes (Figure 7), which are presented sequentially, from left to right, but can also occur in parallel, and can be iterative. These sub-processes are:

        <h3> 1.1. Identify needs </h3> 

            <p> 63.	This sub-process includes the initial investigation and identification of what statistics are needed and what is needed of the statistics. It may be triggered by a new information request from users, an environmental change such as a reduced budget, a periodic review, or respondent feedback. Action plans <a href="#footnote-11">[11]</a> from evaluations of previous iterations of the production cycle (including from respondent feedback) or from other programmes might provide an input to this sub-process. It also includes consideration of practice amongst other (national and international) statistical organisations producing similar data and the methods used by those organisations.

        <h3> 1.2. Consult and confirm needs</h3> 

            <p> 64.	This sub-process focuses on consulting with the internal and external stakeholders and confirming in detail the needs for the statistics. A good understanding of user needs is required so that the statistical organisation knows not only what it is expected to deliver, but also when, how, and perhaps most importantly, why. For the second and subsequent iterations of this sub-process, the main focus will be on determining whether previously identified needs have changed. This detailed understanding of user needs is the critical part of this sub-process.

        <h3> 1.3. Establish output objectives</h3> 

            <p> 65.	This sub-process identifies the statistical output objectives that are required to meet the user needs confirmed in sub-process 1.2 (Consult and confirm needs). It includes agreeing the suitability of the proposed outputs and their quality measures with users. Legal or normative frameworks (e.g. relating to confidentiality, methodologies), and available resources are important to consider when establishing output objectives.

        <h3> 1.4. Identify concepts</h3> 

            <p> 66.	This sub-process clarifies the required concepts to be measured from the point of view of the users. At this stage, the concepts identified might not align with existing statistical standards. This alignment, and the choice or definition of the statistical and other concepts and variables to be used, takes place in sub-process 2.2 (Design variables).

        <h3> 1.5. Check data availability and suitability </h3> 

            <p> 67.	This sub-process checks whether current sources of data could meet user requirements and the conditions under which they would be available, including any restrictions on their use. An assessment of possible alternatives would normally include research into potential administrative or other non-statistical sources of data (e.g. privately-held data or “Big Data”), to: 

                <ul style="list-style-type:disc;">
                    <li> Determine whether they would be suitable for use for statistical purposes (e.g. the extent to which administrative concepts match data requirements, and whether the timeliness and quality of the data, security, and continuity of data supply are suitable); 
                    <li> Assess the division of responsibilities between data suppliers and the statistical organisation; 
                    <li> Check necessary ICT resources (e.g. data storage, technology required to handle incoming data and data processing) as well as any provision agreements with data suppliers (which could be legal or other agreements such as memoranda of understanding) for accessing and sharing the data (e.g. formats, delivery, accompanying metadata and quality check). 
                </ul> 

            <p> 68.	When existing sources have been assessed, a strategy for filling any remaining gaps in the data requirement is prepared. This may include identifying possible partnerships with data holders or conducting a new survey to collect data if necessary. This sub-process also includes a more general assessment of the legal framework in which data would be collected and used, and may therefore identify proposals for changes to existing legislation or the introduction of a new legal framework.

        <h3> 1.6. Prepare and submit business case</h3> 

            <p> 69.	This sub-process documents the findings of the other sub-processes in this phase, in the form of a business case to get approval to implement the new or modified statistical business process. Such a business case would need to conform to the requirements of the approval body, but would typically include elements such as:

                <ul style="list-style-type:disc;">
                    <li> A description of the “As-Is” business process (if it already exists), with information on how the current statistics are produced, highlighting any inefficiencies and issues to be addressed;
                    <li> The proposed “To-Be” solution, detailing how the statistical business process will be developed to produce the new or revised statistics;
                    <li> An assessment of costs and benefits against objectives and any external constraints.
                </ul> 
                
            <p> 70.	The business case describes options and makes recommendations. It may include the benefits, costs, deliverables, time frame, budget, required technical and human resources, risk assessment and impact on stakeholders for each option.

            <p> 71.	After the business case is prepared, it is submitted for approval to move to the next phase of the business process. At this sub-process, a “go”/“no go” decision is made. Typically, the business case is reviewed and formally approved or disapproved by the appropriate sponsors and governance committees.


        <h2> Design Phase </h2> 
            <img src="./img/GSBPMv5.2_Phase2.png" alt="Alt text here">

Figure 8. Design phase and its sub-processes

            <p> 72.	This phase describes the development and design activities, and any associated practical research work needed to define the statistical outputs, variables, methodologies, collection instruments and operational processes, with due regard to other requirements such as security. It includes all the design elements needed to define or refine the statistical products or services identified in the business case. This phase specifies all relevant metadata, in accordance with the standards and corporate policies, ready for use later in the business process, as well as quality assurance procedures. For statistical outputs produced on a regular basis, this phase usually occurs for the first iteration and whenever improvement actions are identified in the Evaluate phase of a previous iteration.

            <p> 73.	Design activities make substantial use of international and national standards in order to reduce the length and cost of the design process, and enhance interoperability, comparability, etc. Organisations may reuse or adapt design elements from existing processes and consider geospatial aspects of data in the design to enhance the usability and value of the statistical information. Additionally, outputs of design processes may form the basis for future standards at the organisational, national or international levels.

            <p> 74.	The Design phase is broken down into six sub-processes (Figure 8), which are presented sequentially, from left to right, but can also occur in parallel, and can be iterative. Some approaches used to develop tools and systems involve iteration between sub-processes in the Design and Build phases. The sub-processes of the Design phase are:

        <h3> 2.1. Design outputs and dissemination</h3> 

            <p> 75.	This sub-process contains the detailed design of the statistical outputs, products and services to be produced, including the related systems, tools and procedures used in the Disseminate phase. Processes governing access to any confidential outputs are also designed here. Outputs should be designed to follow existing standards wherever possible, so inputs to this process may include metadata from similar or previous collections (including extractions from statistical, administrative, geospatial and other non-statistical registers and databases), international standards, and information about practices in other statistical organisations from sub-process 1.1 (Identify needs). Outputs may also be designed in partnership with other interested bodies, particularly if they are considered to be joint outputs, or they will be disseminated by another organisation.

        <h3> 2.2. Design variables </h3> 

            <p> 76.	This sub-process defines the variables to be collected via the collection instrument, as well as any other variables that will be derived from them in sub-process 5.5 (Derive new variables and units), and any statistical or geospatial classifications that will be used. This is also where unit types (including observation units and statistical units) can be designed. It is expected that existing national and international standards will be followed wherever possible. This sub-process may need to run in parallel with sub-process 2.3 (Design collection), as the definition of the variables to be collected and the choice of collection instruments may be inter-dependent to some degree. Preparation of metadata for collected and derived variables, statistical and geospatial classification is a necessary precondition for subsequent phases.

        <h3> 2.3. Design collection</h3> 

            <p> 77.	This sub-process prepares a collection strategy for the data, and determines the most appropriate collection instruments and methods, which may depend on the type of data collection, the collection unit type (enterprise, person, or other) and the available sources of data. The actual activities in this sub-process will vary according to the type of collection instrument required, which can include computer assisted interviewing, paper questionnaires, administrative registers, automated and semi-automated data transfer methods (such as using APIs, machine-to-machine integrations and various types of file transfers), web-scraping technologies as well as technology for geospatial data. The collection may employ a multi-mode method which requires additional considerations such as design of sequencing or different instruments for different modes. Direct or indirect use of administrative data may be introduced in the data collection mode for either controlling survey data or assisting it when capturing survey information. 

            <p> 78.	In the case of survey (or census) data, this collection strategy includes the design of the collection instruments, questions and response templates (in conjunction with the variables and statistical classifications designed in sub-process 2.2 (Design variables)). It is important to understand respondents and incorporate the user perspectives in the design of data collection. This sub-process may include design of fieldwork operations, and respondent engagement, in the case of survey data collection. It also includes the confirmation of existing agreements or creation of new agreements. This sub-process is enabled by tools such as question libraries (to facilitate the reuse of questions and related attributes), questionnaire tools (to enable the quick and easy compilation of questions into formats suitable for cognitive testing) and agreement templates (to help standardise terms and conditions). This sub-process also includes the design of respondent management systems that are specific to this business process. 

            <p> 79.	Where statistical organisations do not collect data directly (i.e. a third party controls the collection and processing of the data), this sub-process may include the design of mechanisms to monitor the data and the metadata to assess impacts of any change made by the third party.

        <h3> 2.4. Design frame and sample</h3> 

            <p> 80.	This sub-process applies especially to processes which involve data collection based on sampling, such as through statistical surveys, but it may also apply to other types of data collection such as census or register-based (e.g., filtering of registers based on the target population). It identifies and specifies the population of interest, defines a sampling frame (and, where necessary, the register from which it is derived), and determines the most appropriate sampling criteria and methodology (which could include complete enumeration). Common sources for a sampling frame are administrative and statistical registers, censuses and information from other sample surveys. It may refer to geospatial data and classifications. This sub-process describes how these sources can be combined if needed. Analysis of whether the frame covers the target population should be performed. Spatial analysis techniques can be used to ensure the spatial distribution of the units is appropriate. A sampling plan should be made. The actual sample is created in sub-process 4.1 (Create frame and select sample), using the methodology specified in this sub-process.

        <h3> 2.5. Design processing and analysis</h3> 

            <p> 81.	This sub-process designs the statistical methodology to be applied during the Process and Analyse phases. This can include, among others, specification of routines and rules for coding, editing and imputation, which may vary based on the means of data collection and source of data. This sub-process also includes design of specifications for data integration from multiple data sources, validation of data and estimation. Statistical disclosure control methods are also designed here if they are specific to this business process.

        <h3> 2.6. Design production systems and workflows</h3> 

            <p> 82.	This sub-process determines the workflow from data collection to dissemination, taking an overview of all the processes required within the whole production process and ensuring that they fit together efficiently with no gaps or redundancies. Various systems and databases may be needed throughout the process. The GSBPM can be used to design a statistical organisation’s business architecture layer when a statistical organisation has an existing enterprise architecture in place. The design might be adjusted to fit the organisation. A general principle is to reuse processes and technology across many statistical business processes, so existing production solutions (e.g. services, systems and databases) should be examined first, to determine whether they are fit for purpose for this specific production process, then, if any gaps are identified, new solutions can be designed. This sub-process also considers how staff will interact with systems and who will be responsible for what and when.


    <h2>  Build Phase  </h2> 


Figure 9. Build phase and its sub-processes

            <p> 83.	This phase builds and tests the production solution to the point where it is ready for use in the “live” environment. The outputs of the Design phase are assembled and configured in this phase to create the complete operational environment to run the process. New services are built by exception, created in response to gaps in the existing catalogue of services sourced from within the organisation and externally. These new services are constructed to be broadly reusable in alignment with the business architecture of the organisation where possible, and compliant with security requirements.

            <p> 84.	For statistical outputs produced on a regular basis, this phase usually occurs for the first iteration, following a review or a change in methodology or technology, rather than for every iteration. 

            <p> 85.	The Build phase is broken down into seven sub-processes (Figure 9), which are presented sequentially, from left to right, but can also occur in parallel, and can be iterative. Some approaches used to develop tools and systems involve iteration between sub-processes in the Design and Build phases. The first three sub-processes are concerned with the development and improvement of systems used in collection, processing, analysis and dissemination of data. The last four sub-processes focus on the end-to-end process. These sub-processes are:

        <h3> 3.1. Reuse or build collection instruments</h3> 

            <p> 86.	This sub-process describes the activities to build and reuse the collection instruments needed during the Collect phase. The collection instruments are built based on the design specifications created during the Design phase. A collection may use one or more collection instruments to receive the data (e.g. personal or telephone interviews; paper, electronic or web questionnaires; SDMX web services). Collection instruments may also be data extraction routines used to gather data from existing statistical or administrative registers (e.g. by using existing service interfaces). This sub-process also includes preparing and testing the contents and functioning of that collection instrument (e.g. cognitive testing of the questions in a questionnaire). It is recommended to consider the direct connection of collection instruments to a metadata system, so that metadata can be more easily captured in the collection phase. Connecting metadata and data at the point of capture can save work in later phases. Capturing the metrics of data collection (paradata) is also an important consideration in this sub-process for calculating and analysing process quality indicators.

        <h3> 3.2. Reuse or build processing and analysis components</h3> 

            <p> 87.	This sub-process describes the activities to reuse existing components or build new components needed for the Process and Analyse phases, as designed in the Design phase. Services (re-)used may include dashboard functions and features, information services, transformation functions, geospatial data services, workflow management tools, respondent and metadata management services.

        <h3> 3.3. Reuse or build dissemination components</h3> 

            <p> 88.	This sub-process describes the activities to build new components or reuse existing components needed for the dissemination of statistical products as designed in sub-process 2.1 (Design outputs and dissemination). All types of dissemination components are included, from those that produce traditional paper publications to those that provide web services, (linked) open data outputs, geospatial statistics, maps, or access to microdata.

        <h3> 3.4. Configure workflows</h3> 

            <p> 89.	This sub-process configures the workflows, systems and transformations used within the business processes, from data collection through to dissemination. In this sub-process, the workflows are configured based on the design created in sub-process 2.6 (Design production systems and workflows). This could include modifying a standardised workflow for a specific purpose, assembling the workflows for the different phases together (possibly with a workflow/business process management system) and configuring systems accordingly. 

        <h3> 3.5. Test production systems</h3> 

            <p> 90.	This sub-process is concerned with the testing of assembled and configured services and related workflows. It includes technical testing and sign-off of new programmes and routines, as well as confirmation that existing routines from other statistical business processes are suitable for use in this case. Whilst part of this activity concerning the testing of individual components and services could logically be linked with sub-processes 3.1 (Reuse or build collection instruments), 3.2 (Reuse or build processing and analysis components) and 3.3 (Reuse or build dissemination components), this sub-process also includes testing of interactions between assembled and configured services and ensuring that the whole production solution works in a coherent way. It can also include arranging secure channels for the transmission of the data, checking detailed information about files and metadata with a data supplier and receiving test files to assess if data are fit for use.

        <h3> 3.6. Test statistical business process</h3> 

            <p> 91.	This sub-process describes the activities to manage a field test or pilot of the statistical business process. Typically, it includes a small-scale data collection, to test the collection instruments, followed by processing and analysis of the collected data, to ensure the statistical business process performs as expected. Following the pilot, it may be necessary to go back to a previous step and make adjustments to collection instruments, systems or components. For a major statistical business process, e.g. a population census, there may be several iterations until the process is working satisfactorily.

        <h3> 3.7. Finalise production systems</h3> 

            <p> 92.	This sub-process includes the activities to put the assembled and configured processes and services, including modified and newly-created services, into production ready for use. The activities include:
                <ul style="list-style-type:disc;">
                    <li> Producing documentation about the process components, including technical documentation and user manuals; </li>
                    <li> Training the users of the system on how to operate the process;</li>
                    <li> Moving the process components into the production environment and ensuring they work as expected in that environment (this activity may also be part of sub-process 3.5 (Test production systems).</li>
                </ul>

    
          <p id="footnote-11">[11] Action plans may arise from sub-process 8.3</p>
    
    
    </section>
    
    
    </body>
</html>
